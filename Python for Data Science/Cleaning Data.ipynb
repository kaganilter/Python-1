{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('filename.csv')\n",
    "\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "\n",
    "print(df.info()) # Information including the column names and type of the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For summary statistics, `.describe()` method can be used. However, it is worth noting that this method can only be used on numeric columns. Another method, `.value_counts()`, can be used for categorical data. It returns the frequency counts for each unique value in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe()) # Summary statistics for all numerical columns\n",
    "print(df['column name'].describe()) # Summary statistics for a specific column\n",
    "\n",
    "print(df['column name'].value_counts(dropna=False)) # dropna=False will give a frequency count of the missing observations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Histogram\n",
    "df['column name'].plot(kind='hist') # = df.column_name.plot('hist')\n",
    "plt.show()\n",
    "\n",
    "# Boxplot\n",
    "df.boxplot(column='column name', by='column name')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot\n",
    "df.plot(kind='scatter', x='column name', y='column name')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidying Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melting Data\n",
    "In melting we turn specific columns into rows. `pd.melt()` is used to reshape the data. _id_vars_ is for variables or columns we do not want to melt, _value_vars_ is for variables we wish to melt into rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_melt = pd.melt(data, id_vars=['Column1', 'Column2'], var_name='rename var column', value_name='rename value column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoting Data\n",
    "In pivoting we turn unique observations (in specific columns) into new columns with `.pivot_table()` method. _index_ parameter can be used to specify the columns that we want to exclude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pivot = data.pivot_table(index=['Column1', 'Column2'], columns='Column_Name', values='Value Column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Row Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df1, df2, df3])  # axis=0 by default (row-wise concatenation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df1, df2, df3], axis = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching and Concatenation Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use wildcards to recognize a pattern to find files. `?` represents any one character, while `*` represents any number of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "all_csv = '*.csv'\n",
    "\n",
    "csvs = glob.glob(all_csv)\n",
    "\n",
    "print(csvs)\n",
    "\n",
    "list_csvs = []\n",
    "\n",
    "for csv in csvs:\n",
    "    df = pd.read_csv(csv)\n",
    "    list_csvs.append(df)\n",
    "\n",
    "df_all = pd.concat(list_csvs)\n",
    "\n",
    "print(df_all.shape)\n",
    "print(df_all.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge two DataFrames (values may be duplicated when necessary)\n",
    "merge2 = pd.merge(left=left_df, right=right_df, left_on='column_on_left', right_on='column_on_right') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking and Coverting Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, columns in a dataset is recognized as an object instead of a category. We need to change such variables to categorical variables. Here we use `.astype()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.info() # See the types of the variables.\n",
    "\n",
    "ds.column_name = ds.column_name.astype('category')\n",
    "\n",
    "print(ds.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may also be necessary to change the datatype to a numeric type. `pd.to_numeric()` function can be used to do that. Note that the function may raise an error if there are missing or wrong values. `errors='coerce'` changes these values into missing values NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['column_name'] = pd.to_numeric(ds['column_name'], errors = 'coerce')\n",
    "\n",
    "print(ds.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import re # regular expression module\n",
    "\n",
    "comp = re.compile('\\d{2}\\.\\d{2}\\.\\d{4}') #\\d is used to find digits.\n",
    "\n",
    "check1 = comp.match('27.09.1538') # check if the pattern matches.\n",
    "print(bool(check1))\n",
    "\n",
    "# See if the pattern matches\n",
    "check2 = comp.match('1980.12.10')\n",
    "print(bool(check2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting numbers from strings: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '13']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "nums = re.findall('\\d+', '2 apples and 13 oranges') # '+' sign used to match '13' together as one number. \n",
    "\n",
    "print(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use _regular expressions_ also to match capital letters, alphanumeric characters etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "check = bool(re.match(pattern='[A-Z]\\w*', string='Ankara1923'))\n",
    "print(check)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
